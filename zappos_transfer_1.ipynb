{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPool2D,Dense,Dropout,Flatten,Input\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.4-tf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this fits the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler,EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "from os.path import isfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16,VGG19\n",
    "from tensorflow.keras.models import Model\n",
    "#from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def no_transfer_model(num_classes,input_shape):\n",
    "    '''Implementation of vgg11 architecture '''\n",
    "\n",
    "    X_in = Input(input_shape)\n",
    "    X = Conv2D(64,3,activation='relu',padding='same')(X_in)\n",
    "    X = MaxPool2D(pool_size=(2,2))(X)\n",
    "    X = Conv2D(128,3,activation='relu',padding='same')(X)\n",
    "    X = MaxPool2D(pool_size=(2,2))(X)\n",
    "    X = Conv2D(256,3,activation='relu',padding='same')(X)\n",
    "    X = Conv2D(256,3,activation='relu',padding='same')(X)\n",
    "    X = MaxPool2D(pool_size=(2,2))(X)\n",
    "    X = Conv2D(512,3,activation='relu',padding='same')(X)\n",
    "    X = Conv2D(512,3,activation='relu',padding='same')(X)\n",
    "    X = MaxPool2D(pool_size=(2,2))(X)\n",
    "    X = Conv2D(256,3,activation='relu',padding='same')(X)\n",
    "    X = Conv2D(512,3,activation='relu',padding='same')(X)\n",
    "    X = MaxPool2D(pool_size=(2,2))(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(4096,activation='relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(4096,activation='relu')(X)\n",
    "    X_out = Dense(num_classes,activation='softmax')(X)\n",
    "    model = Model(input = X_in, output = X_out)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def model(model_name, num_classes, is_transfer, num_freeze_layer, weights_path,input_shape):\n",
    "\n",
    "#     # vgg16_model\n",
    "#     conv_base_16 = VGG16(weights='imagenet',include_top=False,input_shape=input_shape)\n",
    "#     #conv_base_16.summary()\n",
    "\n",
    "\n",
    "    #graph = tf.compat.v1.get_default_graph()\n",
    "\n",
    "    if not is_transfer or model_name == 'simple':\n",
    "        model = no_transfer_model(num_classes,input_shape)\n",
    "        print('how did i get here')\n",
    "        return model        \n",
    "    \n",
    "    \n",
    "#     if model_name == 'vgg_16':\n",
    "#         conv_base_16 = VGG16(weights='imagenet',include_top=False,input_shape=input_shape)\n",
    "#         model = conv_base_16\n",
    "#     elif model_name == 'vgg_19':\n",
    "#         conv_base_19 = VGG19(weights='imagenet',include_top=False,input_shape=input_shape)\n",
    "#         model = conv_base_19\n",
    "#     elif model_name == 'mnNet_v2':\n",
    "#         mobileNet_v2 = MobileNetV2(weights='imagenet',include_top=False,input_shape=input_shape,pooling = 'avg')\n",
    "#         model = mobileNet_v2\n",
    "    if model_name == 'mnNet_v2':\n",
    "        mobileNet_v2 = MobileNetV2(weights='imagenet',include_top=False,input_shape=input_shape,pooling = 'avg')\n",
    "        model = mobileNet_v2\n",
    "    # final_model\n",
    "    #global graph \n",
    "    #graph = tf.get_default_graph()\n",
    "  \n",
    "    print(model_name) \n",
    "    print(weights_path)\n",
    "    print('------x-x-x-x-x-x---x-xx-x-x-x-xx------')   \n",
    "    print(input_shape) \n",
    "\n",
    "    # freeze the given number of layers\n",
    "    for layer in model.layers[:num_freeze_layer]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Adding custom layers # maybe have a problem with the mobileNet_v2 output?\n",
    "    m_out = model.output\n",
    "\n",
    "    m_flatten = Flatten()(m_out)\n",
    "    m_dense = Dense(1024,activation='relu')(m_flatten)\n",
    "    m_drop = Dropout(0.5)(m_dense)\n",
    "    m_dense = Dense(1024,activation='relu')(m_drop)\n",
    "    pred_out = Dense(num_classes,activation='softmax')(m_dense)\n",
    "\n",
    "    # final_model\n",
    "    #with graph.as_default():\n",
    "    #    final_model = Model(input=model.input,output=pred_out)\n",
    "    final_model = Model(input=model.input,output=pred_out)\n",
    "\n",
    "    print(final_model.summary())\n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# these functions set up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img,img_to_array\n",
    "from os.path import isdir,abspath,join\n",
    "from os import listdir\n",
    "\n",
    "data_path = './data/' # path of the data\n",
    "train_path = './train'\n",
    "test_path = './test'\n",
    "\n",
    "def load_img_arr(p):\n",
    "    return img_to_array(load_img(p))\n",
    "\n",
    "\n",
    "def train_val_generator(\n",
    "    batch_size, train_path,test_path,target_size=(136,136)):\n",
    "\n",
    "    gen_tr = _train_generator()\n",
    "    gen_val = _val_generator()\n",
    "\n",
    "    sample = apply_to_images_in_subdirs(train_path,load_img_arr,num_per_cls = batch_size)\n",
    "    sample = np.array(sample)\n",
    "    gen_tr.fit(sample)\n",
    "    gen_val.fit(sample)\n",
    "\n",
    "    gen_tr = init_directory_generator(\n",
    "        gen_tr,train_path,batch_size,target_size=target_size)\n",
    "\n",
    "    gen_val = init_directory_generator(\n",
    "        gen_val,test_path,batch_size,target_size=target_size)\n",
    "\n",
    "    return gen_tr,gen_val\n",
    "\n",
    "\n",
    "def _train_generator():\n",
    "    return ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        rotation_range=180,\n",
    "        zoom_range=0.2,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='reflect'\n",
    "    )\n",
    "\n",
    "\n",
    "def _val_generator():\n",
    "    return ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True\n",
    "    )\n",
    "\n",
    "def apply_to_images_in_subdirs(parent_dir, func, num_per_cls=None, **kwargs):\n",
    "    results = []\n",
    "    for cls_dir_name in listdir(parent_dir):\n",
    "        cls_dir = abspath(join(parent_dir, cls_dir_name))\n",
    "        r = _apply_to_first_n_in_dir(func, cls_dir, num_per_cls, **kwargs)\n",
    "        results += r\n",
    "    return results\n",
    "\n",
    "\n",
    "def _apply_to_first_n_in_dir(func, dir_, num_per_cls, **kwargs):\n",
    "    if not isdir(dir_):\n",
    "        return []\n",
    "    results = []\n",
    "    for path in listdir(dir_)[:num_per_cls]:\n",
    "        abspath_ = abspath(join(dir_, path))\n",
    "        result = func(abspath_, **kwargs)\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def init_directory_generator(\n",
    "    gen, dir_,batch_size, target_size=(136,136),\n",
    "    class_mode='categorical',shuffle=True):\n",
    "\n",
    "    return gen.flow_from_directory(\n",
    "        dir_,\n",
    "        class_mode = class_mode,\n",
    "        batch_size = batch_size,\n",
    "        target_size = target_size,\n",
    "        shuffle = shuffle\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this fits the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnNet_v2\n",
      "mnNet_v2_weights_tf.h5\n",
      "------x-x-x-x-x-x---x-xx-x-x-x-xx------\n",
      "(224, 224, 3)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "('Keyword argument not understood:', 'input')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-14f96e5e0fd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# model for traning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtr_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mis_transfer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_freeze_layer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# train and test generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-78137f625dc6>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(model_name, num_classes, is_transfer, num_freeze_layer, weights_path, input_shape)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m#with graph.as_default():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;31m#    final_model = Model(input=model.input,output=pred_out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0mfinal_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpred_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zapposGPU/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;31m# initializing _distribution_strategy here since it is possible to call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zapposGPU/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m       \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_subclassed_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_no_legacy_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zapposGPU/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zapposGPU/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_subclassed_network\u001b[0;34m(self, name, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_init_subclassed_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_call_fn_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zapposGPU/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zapposGPU/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_base_init\u001b[0;34m(self, name, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     generic_utils.validate_kwargs(kwargs, {'trainable', 'dtype', 'dynamic',\n\u001b[0;32m--> 197\u001b[0;31m                                            'autocast'})\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# Object to store all thread local layer properties.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/zapposGPU/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mvalidate_kwargs\u001b[0;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[1;32m    597\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'input')"
     ]
    }
   ],
   "source": [
    "model_name ='mnNet_v2' #'vgg_16','vgg_19','mnNet_v2','resnet_152','simple'])\n",
    "is_transfer=True\n",
    "num_freeze_layer=5\n",
    "num_classes=4\n",
    "weights_path='mnNet_v2_weights_tf.h5'\n",
    "input_shape=(224,224,3)#(img_width,img_height,img_channel)')\n",
    "batch_size=32\n",
    "train_path='./train'\n",
    "test_path='./test'\n",
    "\n",
    "\n",
    "# model for traning\n",
    "tr_model = model(model_name,num_classes,is_transfer, num_freeze_layer,weights_path,input_shape)\n",
    "\n",
    "# train and test generator\n",
    "train_gen, val_gen = train_val_generator(batch_size,train_path,test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobileNet_v2 = MobileNetV2(weights='imagenet',include_top=False,input_shape=input_shape,pooling = 'avg')\n",
    "model = mobileNet_v2\n",
    "\n",
    "\n",
    "model2 = no_transfer_model(num_classes,input_shape)\n",
    "\n",
    "print(model2.summary())\n",
    "\n",
    "num_freeze_layers=5\n",
    "print(num_freeze_layers)\n",
    "# global graph \n",
    "# graph = tf.compat.v1.get_default_graph()\n",
    "\n",
    "print(model_name) \n",
    "print(weights_path)\n",
    "print('------x-x-x-x-x-x---x-xx-x-x-x-xx------')   \n",
    "print(input_shape) \n",
    "\n",
    "# freeze the given number of layers\n",
    "for layer in model.layers[:num_freeze_layer]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Adding custom layers # maybe have a problem with the mobileNet_v2 output?\n",
    "m_out = model.output\n",
    "\n",
    "m_flatten = Flatten()(m_out)\n",
    "m_dense = Dense(1280,activation='relu')(m_flatten)\n",
    "m_drop = Dropout(0.5)(m_dense)\n",
    "m_dense = Dense(1024,activation='relu')(m_drop)\n",
    "pred_out = Dense(num_classes,activation='softmax')(m_dense)\n",
    "\n",
    "# final_model\n",
    "with graph.as_default():\n",
    "    final_model = tf.compat.v1.keras.Model(input=model.input,output=pred_out)\n",
    "\n",
    "print(final_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deal with the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import iglob\n",
    "from os.path import join,basename\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "data_path = './data/' # path of the data\n",
    "train_path = './train'\n",
    "test_path = './test'\n",
    "\n",
    "# create training set\n",
    "print('_'*30)\n",
    "print('Creating training set....')\n",
    "print('_'*30)\n",
    "\n",
    "print('already created!! training set....')\n",
    "print('_'*30)\n",
    "\n",
    "\n",
    "# for file in iglob(join(data_path,'*')):\n",
    "\n",
    "#     save_path = join(train_path,basename(file))\n",
    "#     if not os.path.exists(save_path):\n",
    "#         os.makedirs(save_path)\n",
    "\n",
    "#     for img in iglob(join(join(join(file,'*'),'*'),'*')):\n",
    "         \n",
    "\n",
    "#             shutil.copy2(img,save_path)\n",
    "#         print(img) \n",
    "\n",
    "        \n",
    "        \n",
    "# create test set\n",
    "print('_'*30)\n",
    "print('Creating test set....')\n",
    "print('_'*30)\n",
    "\n",
    "print('already created!! test  set....')\n",
    "print('_'*30)\n",
    "\n",
    "# for file in iglob(join(train_path,'*')):\n",
    "#     save_path = join(test_path, basename(file))\n",
    "#     if not os.path.exists(save_path):\n",
    "#         os.makedirs(save_path)\n",
    "    \n",
    "#     total_imgs = [x for x in iglob(join(file,'*'))]\n",
    "\n",
    "#     rand_amt = 0.15 * len(total_imgs)  # select 15% of data from each category as testing set\n",
    "#     test_imgs= []\n",
    "#     for i in range(int(rand_amt)):\n",
    "#         img = random.choice(total_imgs)\n",
    "#         if img not in test_imgs:\n",
    "#             shutil.move(img,save_path)\n",
    "#             test_imgs.append(img)\n",
    "#         print(img)\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load last model if exists\n",
    "model_name = args.model_name+'.h5'\n",
    "if isfile(model_name):\n",
    "    print('Loading previously trained weights and continue traning.....')\n",
    "    tr_model = load_model(model_name)\n",
    "else:\n",
    "    print('No saved weights found.')\n",
    "\n",
    "# model saving\n",
    "checkpoint = ModelCheckpoint(args.model_name+'.h5',monitor='val_acc',verbose=1,save_best_only=True)\n",
    "early_stop = EarlyStopping(monitor='val_acc',min_delta=0,patience=10,verbose=1,mode='auto')\n",
    "\n",
    "# Compile the model\n",
    "tr_model.compile(loss='categorical_crossentropy',optimizer=Adam(1e-5),metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "history = tr_model.fit_generator(\n",
    "                train_gen,\n",
    "                steps_per_epoch=800,\n",
    "                epochs=30,\n",
    "                validation_data = val_gen,\n",
    "                validation_steps = 250,\n",
    "                callbacks = [checkpoint,early_stop])\n",
    "\n",
    "# plot the results\n",
    "plt.figure()\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model_accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'])\n",
    "plt.savefig(args.model_name+'.jpg')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:zapposGPU] *",
   "language": "python",
   "name": "conda-env-zapposGPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
