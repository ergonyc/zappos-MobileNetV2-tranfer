{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://vision.cs.utexas.edu/projects/finegrained/utzap50k/ut-zap50k-images-square.zip!wget http://vision.cs.utexas.edu/projects/finegrained/utzap50k/ut-zap50k-data.zip\n",
    "# !unzip ut-zap50k-images-square.zip\n",
    "# !unzip ut-zap50k-data.zip\n",
    "\n",
    "#Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "#from tqdm import tqdm_notebook\n",
    "import os\n",
    "from glob import glob\n",
    "from os.path import isdir,abspath,join\n",
    "from os import listdir\n",
    "\n",
    "\n",
    "#import numpy as np\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler,EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# from keras.preprocessing import image\n",
    "# from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "#from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "# from keras.applications import imagenet_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "today = datetime.today()\n",
    "\n",
    "\n",
    "df_filename = './summary_Jan-29-2020.pkl'\n",
    "#df = pd.read_pickle(df_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.getcwd()\n",
    "os.chdir('sneaks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b666bf274d0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_summary_file = f'./summary_Jan-29-2020.json'\n",
    "#df = pd.read_json(json_summary_file)\n",
    "\n",
    "summary_file ='summary_withFeatures_Jan-29-2020.pkl'\n",
    "#\n",
    "df = pd.read_pickle(summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_base = '/home/ergonyc/Projects/Insight/UTzappos50k/sneaks'\n",
    "database_path = db_base + '/'+ 'summary_Jan-29-2020_processed.json'\n",
    "database_json = json.load(open(database_path))\n",
    "database_df = pd.DataFrame(database_json)\n",
    "\n",
    "#df2= df.rename(columns={'image_features':'image_features_y'})\n",
    "\n",
    "# COMBINE meta_data and categories.  then iterate over all files to get vector\n",
    "\n",
    "#df['image_features']=df['image_features_x'].copy()  # freaking renaming didn't work!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_features'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.24638242, ..., 0.        , 0.0612052 ,\n",
       "       0.        ], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "database = df\n",
    "size_filter_frame = database.shape[0]\n",
    "num_neighs = 10\n",
    "\n",
    "\n",
    "features = database['image_features_x']\n",
    "features[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_features = (features[10])\n",
    "\n",
    "#Fit Nearest Neighbor Model\n",
    "database_features = np.vstack(database['image_features_x'])\n",
    "\n",
    "neighs = NearestNeighbors(n_neighbors=num_neighs) \n",
    "neighs.fit(database_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query_features.shape)\n",
    "query2 =query_features.reshape(1,-1)\n",
    "print(query2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance, nn_index = neighs.kneighbors(query_features.reshape(1,-1), return_distance=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_index\n",
    "nn_index.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get nearest neighbor subset\n",
    "neighbors = \n",
    "neighbor_pd = []\n",
    "neighbor_pd = df.iloc[0]\n",
    "for row in range(1,10): \n",
    "    neighbor_pd.concat(df.iloc[row])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_pd = database.iloc[nn_index.tolist()[0]]\n",
    "neighbor_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "size_filter_frame = database.shape[0]\n",
    "num_neighs = min(num_neighs, size_filter_frame)\n",
    "\n",
    "#Fit Nearest Neighbor Model\n",
    "database_features = np.vstack(df['image_features'])\n",
    "neighs = NearestNeighbors(n_neighbors=num_neighs+1) #add plus one in case image exists in database\n",
    "neighs.fit(database_features)\n",
    "distance, nn_index = neighs.kneighbors(query_features, return_distance=True)\n",
    "\n",
    "    #Check to see if image is already in dabase and remove (see if distance == 0)\n",
    "    #If True, remove n = 0, and take n+1 neighbor\n",
    "    if remove_dup: \n",
    "        updated_nn_index = []\n",
    "        for i,row in enumerate(distance):\n",
    "            image_exists = len(nn_index[i, row!=0]) == num_neighs\n",
    "            if image_exists: \n",
    "                new_in= nn_index[i,1:num_neighs+1]\n",
    "            else: \n",
    "                new_in = nn_index[i,0:num_neighs]\n",
    "        \n",
    "            updated_nn_index.append(new_in)\n",
    "    \n",
    "        nn_index = np.array(updated_nn_index)\n",
    "    \n",
    "    #Get pandas dataframes\n",
    "    panda_list = []\n",
    "    for row in nn_index: \n",
    "        panda_list.append(price_filter_df.iloc[row])\n",
    "    \n",
    "    #Get nearest neighbor result urls \n",
    "    url_matrix = []\n",
    "    for row in nn_index: \n",
    "        url_row = price_filter_df['image_url'].values[row]\n",
    "        url_matrix.append(url_row)\n",
    "    \n",
    "    url_matrix = np.array(url_matrix)\n",
    "\n",
    "    #concat query image array to result arrays \n",
    "    images_urls = np.concatenate([query_image, url_matrix], axis = 1)\n",
    "\n",
    "    if fig_plot: \n",
    "        get_fig_plots(images_urls)\n",
    "\n",
    "    return(nn_index, images_urls, panda_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwidth = 224\n",
    "pheight = 224 #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train and test generator\n",
    "#train_gen, val_gen = train_val_generator(batch_size, train_path, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenetv2_1.00_224\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, 225, 225, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 112, 112, 32) 864         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1280)         0           out_relu[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 2,223,872\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# #from utils import train_val_generator\n",
    "data_path = './data/' # path of the data\n",
    "train_path = './train'\n",
    "test_path = './test'\n",
    "\n",
    "TARGET_SZ = 224\n",
    "\n",
    "input_shape = (TARGET_SZ,TARGET_SZ,3) #(img_width,i mg_height,img_channel)')\n",
    "#batch_size = 32\n",
    "\n",
    "cnn_model = MobileNetV2(weights = 'imagenet', \n",
    "                            include_top = False, \n",
    "                            input_shape = input_shape, \n",
    "                            pooling = 'avg')\n",
    "\n",
    "model_name = 'MobileNetV2'\n",
    "# with graph.as_default():\n",
    "#     img_features = network_model.predict(img_vector)\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,['Category.Boots','Category.Sandals','Category.Shoes','Category.Slippers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "%matplotlib inline\n",
    "\n",
    "#Start assessing models. Try a family of models to identify the best performers \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BINARY ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BINARY ENCODER Shoes or Not\n",
    "\n",
    "# start by predicting shoes versus \"other\"\n",
    "labels = pd.DataFrame(df['Category.Shoes'])\n",
    "\n",
    "#Combine Data, get test/train split \n",
    "image_features = pd.DataFrame((df['image_features']))\n",
    "\n",
    "X_train_pd, X_test_pd, Y_train_pd, Y_test_pd = train_test_split(image_features, \n",
    "                                                                labels, \n",
    "                                                                test_size = 0.3, \n",
    "                                                                random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vstack(X_train_pd['image_features'])\n",
    "X_test  = np.vstack(X_test_pd['image_features'])\n",
    "Y_train = Y_train_pd.values.flatten()\n",
    "Y_test  = Y_test_pd.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate diffent classifier types\n",
    "clf_logit = LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter = 1200)\n",
    "ridge_model = RidgeClassifier(max_iter = 1000)\n",
    "\n",
    "neighbors = [1,3,5]\n",
    "knn_models = [KNeighborsClassifier(n_neighbors=num) for num in neighbors]\n",
    "\n",
    "n_estimators = [10,100,500]\n",
    "forest_model = RandomForestClassifier(n_estimators=500, )\n",
    "\n",
    "models = [clf_logit, ridge_model, knn_models[0], knn_models[1], knn_models[2], forest_model]\n",
    "model_names = ['logistic','ridge', 'knn_1', 'knn_3', 'knn_5', 'forest_model']\n",
    "\n",
    "\n",
    "#Determine Model Scores\n",
    "avg_scores = []\n",
    "std_scores = []\n",
    "for clf, name in zip(models, model_names): \n",
    "    print('training: ', name, ' model')\n",
    "    scores = cross_val_score(clf, X_train, Y_train, cv = 5)\n",
    "    avg_scores.append(np.mean(scores))\n",
    "    std_scores.append(np.std(scores))\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_scores)\n",
    "print(std_scores)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Model Results \n",
    "plt.bar(model_names, avg_scores,yerr = std_scores)\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('Classifier_Comparison.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine tune Log model\n",
    "import math\n",
    "alpha = [0.1, 1,10]\n",
    "log_avg = []\n",
    "log_std = []\n",
    "for a in alpha: \n",
    "    print('log model with C =', a)\n",
    "    clf_log = LogisticRegression(C=a, multi_class='ovr', solver='lbfgs', max_iter=2000)\n",
    "    scores_ridge = cross_val_score(clf_log, X_train, Y_train, cv = 5)\n",
    "    log_avg.append(np.mean(scores_ridge))\n",
    "    log_std.append(np.std(scores_ridge))\n",
    "\n",
    "print(log_avg)\n",
    "print(log_std)\n",
    "\n",
    "\n",
    "#Plot Model Results \n",
    "plt.bar(alpha, log_avg,yerr = log_std)\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('Classifier_Comparison.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from seaborn import heatmap\n",
    "\n",
    "\n",
    "#Display Confusion Matrix\n",
    "X_test = np.vstack(X_test_pd['image_features'])\n",
    "\n",
    "clf_log = LogisticRegression(C = 1, multi_class='ovr', max_iter=2000, solver='lbfgs')\n",
    "clf_log.fit(X_train, Y_train)\n",
    "log_score = clf_log.score(X_test, Y_test)\n",
    "log_ypred = clf_log.predict(X_test)\n",
    "log_confusion_matrix = confusion_matrix(Y_test, log_ypred)\n",
    "print(log_confusion_matrix)\n",
    "\n",
    "heatmap(log_confusion_matrix, annot=True, linewidths=0.5, cmap='Blues')\n",
    "plt.savefig('log_Matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#See where classifiers are messing up \n",
    "panda_ints = Y_test_pd.index.values\n",
    "class_labels = [0,1]\n",
    "\n",
    "performance_matrix = []\n",
    "for row in class_labels: \n",
    "    bool_truth = (Y_test == row) \n",
    "    for column in class_labels: \n",
    "        bool_pred = (log_ypred==column)\n",
    "        performance_logical = np.logical_and(bool_truth, bool_pred)\n",
    "        performance_ints = panda_ints[performance_logical==True]\n",
    "        performance_matrix.append(performance_ints)\n",
    "        \n",
    "for num, entry in enumerate(performance_matrix): \n",
    "    plt.subplot(2,2,num +1)\n",
    "    rand_int = random.randint(0,len(entry)-1)\n",
    "    index = entry[rand_int]\n",
    "    path = data_path+df['path'][index]\n",
    "    img_data = image.load_img(path, target_size=(224, 224))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img_data);    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "#Save Trained model to disk\n",
    "filename = f'log_model_{today:%b-%d-%Y}.sav'\n",
    "joblib.dump(clf_log, filename)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CATEGORICAL LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### now do the test in 4 categories\n",
    "\n",
    "labels = df.loc[:,['Category.Boots','Category.Sandals','Category.Shoes','Category.Slippers']]\n",
    "\n",
    "X_train_pd, X_test_pd, Y_train_pd, Y_test_pd = train_test_split(image_features, \n",
    "                                                                labels, \n",
    "                                                                test_size = 0.3, \n",
    "                                                                random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pd.values\n",
    "\n",
    "X_train = np.vstack(X_train_pd['image_features'])\n",
    "X_test  = np.vstack(X_test_pd['image_features'])\n",
    "Y_train = Y_train_pd.values.flatten()\n",
    "Y_test  = Y_test_pd.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate diffent classifier types\n",
    "clf_logit = LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter = 1000)\n",
    "ridge_model = RidgeClassifier(max_iter = 1000)\n",
    "\n",
    "neighbors = [1,3,5]\n",
    "knn_models = [KNeighborsClassifier(n_neighbors=num) for num in neighbors]\n",
    "\n",
    "n_estimators = [10,100,500]\n",
    "forest_model = RandomForestClassifier(n_estimators=500, )\n",
    "\n",
    "models = [clf_logit, ridge_model, knn_models[0], knn_models[1], knn_models[2], forest_model]\n",
    "model_names = ['logistic','ridge', 'knn_1', 'knn_3', 'knn_5', 'forest_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine Model Scores\n",
    "avg_scores = []\n",
    "std_scores = []\n",
    "for clf, name in zip(models, model_names): \n",
    "    print('training: ', name, ' model')\n",
    "    scores = cross_val_score(clf, X_train, Y_train, cv = 5)\n",
    "    avg_scores.append(np.mean(scores))\n",
    "    std_scores.append(np.std(scores))\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_scores)\n",
    "print(std_scores)\n",
    " \n",
    "\n",
    "#Plot Model Results \n",
    "plt.bar(model_names, avg_scores,yerr = std_scores)\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('Classifier_Comparison.png')\n",
    "\n",
    "#Fine tune Log model\n",
    "import math\n",
    "alpha = [0.1, 1,10]\n",
    "log_avg = []\n",
    "log_std = []\n",
    "for a in alpha: \n",
    "    print('log model with C =', a)\n",
    "    clf_log = LogisticRegression(C=a, multi_class='ovr', solver='lbfgs', max_iter=2000)\n",
    "    scores_ridge = cross_val_score(clf_log, X_train, Y_train, cv = 5)\n",
    "    log_avg.append(np.mean(scores_ridge))\n",
    "    log_std.append(np.std(scores_ridge))\n",
    "\n",
    "print(log_avg)\n",
    "print(log_std)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from seaborn import heatmap\n",
    "\n",
    "\n",
    "#Display Confusion Matrix\n",
    "X_test = np.vstack(X_test_pd['image_features'])\n",
    "\n",
    "clf_log = LogisticRegression(C = 1, multi_class='ovr', max_iter=2000, solver='lbfgs')\n",
    "clf_log.fit(X_train, Y_train)\n",
    "log_score = clf_log.score(X_test, Y_test)\n",
    "log_ypred = clf_log.predict(X_test)\n",
    "log_confusion_matrix = confusion_matrix(Y_test, log_ypred)\n",
    "print(log_confusion_matrix)\n",
    "\n",
    "heatmap(log_confusion_matrix, annot=True, linewidths=0.5, cmap='Blues')\n",
    "plt.savefig('log_Matrix.png')\n",
    "\n",
    "import random\n",
    "\n",
    "#See where classifiers are messing up \n",
    "panda_ints = Y_test_pd.index.values\n",
    "class_labels = [0,1,2]\n",
    "\n",
    "performance_matrix = []\n",
    "for row in class_labels: \n",
    "    bool_truth = (Y_test == row) \n",
    "    for column in class_labels: \n",
    "        bool_pred = (log_ypred==column)\n",
    "        performance_logical = np.logical_and(bool_truth, bool_pred)\n",
    "        performance_ints = panda_ints[performance_logical==True]\n",
    "        performance_matrix.append(performance_ints)\n",
    "        \n",
    "for num, entry in enumerate(performance_matrix): \n",
    "    plt.subplot(3,3,num +1)\n",
    "    rand_int = random.randint(0,len(entry)-1)\n",
    "    index = entry[rand_int]\n",
    "    path = all_dataframes['image_file_path'][index]\n",
    "    img_data = image.load_img(path, target_size=(224, 224))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img_data);    \n",
    "    \n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "#Save Trained model to disk\n",
    "filename = f'log_model_{today:%d-%d-%2190621.sav'\n",
    "joblib.dump(clf_log, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random \n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "def nearest_neighbor_image_finder(query_image, query_features, num_neighs, database, fig_plot): \n",
    "    ''' function to return nearest neighbors for a query\n",
    "    \n",
    "    Args: \n",
    "        query_image (image): image \n",
    "        query_features (array): numpy array of extracted image features\n",
    "        num_neighs (int): number of neighbors to return \n",
    "        datbase(df): pandas dataframe containing image database\n",
    "        fig_plot (bool): boolean to indicate of plotting is desired (1 for yes)\n",
    "        #min_price (float): minimum budget\n",
    "        #max_price (float): max budget\n",
    "        #remove_dup (bool): remove image from database if it exists\n",
    "    \n",
    "    return: \n",
    "        nn_results (arr): indices of nearest_neighbor lookup\n",
    "        images_urls (arr): array of image urls for query and nearest neighbors sorted in nearest neighbor order\n",
    "        pandas_list (pd): pandas dataframe containing all relevant information of neighbors \n",
    "    '''\n",
    "    \n",
    "    remove_dup = True\n",
    "    \n",
    "    #logic here in case the n exceeds number of items in database\n",
    "    size_filter_frame = database.shape[0]\n",
    "    num_neighs = min(num_neighs, size_filter_frame)\n",
    "    \n",
    "    #Fit Nearest Neighbor Model\n",
    "    database_features = np.vstack(database['image_features'])\n",
    "    neighs = NearestNeighbors(n_neighbors=num_neighs+1) #add plus one in case image exists in database\n",
    "    neighs.fit(database_features)\n",
    "    distance, nn_index = neighs.kneighbors(query_features, return_distance=True)\n",
    "    \n",
    "    #Check to see if image is already in dabase and remove (see if distance == 0)\n",
    "    #If True, remove n = 0, and take n+1 neighbor\n",
    "    if remove_dup: \n",
    "        updated_nn_index = []\n",
    "        for i,row in enumerate(distance):\n",
    "            image_exists = len(nn_index[i, row!=0]) == num_neighs\n",
    "            if image_exists: \n",
    "                new_in= nn_index[i,1:num_neighs+1]\n",
    "            else: \n",
    "                new_in = nn_index[i,0:num_neighs]\n",
    "        \n",
    "            updated_nn_index.append(new_in)\n",
    "    \n",
    "        nn_index = np.array(updated_nn_index)\n",
    "    \n",
    "    #Get pandas dataframes\n",
    "    panda_list = []\n",
    "    for row in nn_index: \n",
    "        panda_list.append(price_filter_df.iloc[row])\n",
    "    \n",
    "    #Get nearest neighbor result urls \n",
    "    url_matrix = []\n",
    "    for row in nn_index: \n",
    "        url_row = price_filter_df['image_url'].values[row]\n",
    "        url_matrix.append(url_row)\n",
    "    \n",
    "    url_matrix = np.array(url_matrix)\n",
    "\n",
    "    #concat query image array to result arrays \n",
    "    images_urls = np.concatenate([query_image, url_matrix], axis = 1)\n",
    "\n",
    "    if fig_plot: \n",
    "        get_fig_plots(images_urls)\n",
    "\n",
    "    return(nn_index, images_urls, panda_list)  \n",
    "            \n",
    "def get_fig_plots(image_urls):\n",
    "    ''' function to plot matrix of image urls. \n",
    "        image_urls[:,0] should be the query image\n",
    "        \n",
    "    Args: \n",
    "        image_urls: matrix of image urls\n",
    "    \n",
    "    return: \n",
    "        null\n",
    "        saves image file to directory\n",
    "    '''\n",
    "    nrow = image_urls.shape[0]\n",
    "    ncol = image_urls.shape[1]\n",
    "    flat_urls = image_urls.flatten()\n",
    "\n",
    "    fig = plt.figure(figsize = (20, 20))\n",
    "\n",
    "    for num,url in enumerate(flat_urls):\n",
    "    \n",
    "        response = requests.get(url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        img = img.resize((224,224), Image.ANTIALIAS)\n",
    "        plt.subplot(nrow, ncol, num+1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img);\n",
    "\n",
    "        if num == 0: \n",
    "            plt.title('Query')\n",
    "    \n",
    "        if 0<num <ncol: \n",
    "            plt.title('Neighbor ' + str(num))\n",
    "        \n",
    "    plt.savefig('image_search.png')\n",
    "        \n",
    "    \n",
    "            \n",
    "#Test Nearest Neighbor lookup with random selection from database, plot results \n",
    "n_queries = 1\n",
    "query_inds = []\n",
    "random.seed(150)\n",
    "[query_inds.append(random.randint(i,12000)) for i in range(n_queries)]\n",
    "\n",
    "query_features = np.vstack(image_df['image_features'][query_inds])\n",
    "query_url = np.array(image_df['image_url'][query_inds]).reshape(n_queries,1)\n",
    "num_neigs = 5\n",
    "fig_plot = 1\n",
    "indices, urls, subset_pd = nearest_neighbor_image_finder(query_url, query_features, num_neighs, image_df,fig_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOW A FEW THINGS\n",
    "# train the model to \"classify\" (for validation)\n",
    "# use the pre-trained model to look at how the features are distributed in space from MobileNetV2\n",
    "\n",
    "print(tr_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model saving\n",
    "checkpoint = ModelCheckpoint(model_name+'.h5',monitor='val_acc',verbose=1,save_best_only=True)\n",
    "early_stop = EarlyStopping(monitor='val_acc',min_delta=0,patience=10,verbose=1,mode='auto')\n",
    "\n",
    "# Compile the model\n",
    "#adam = Adam()\n",
    "tr_model.compile(loss='categorical_crossentropy', optimizer = \"nadam\" ,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "history = tr_model.fit_generator(\n",
    "                train_gen,\n",
    "                steps_per_epoch=1000,\n",
    "                epochs=30,\n",
    "                validation_data = val_gen,\n",
    "                validation_steps = 250,\n",
    "                callbacks = [checkpoint, early_stop] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "plt.figure()\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model_accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'])\n",
    "plt.savefig(args.model_name+'.jpg')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def central_crop(image):\n",
    "    shape = tf.shape(image)\n",
    "    min_dim = tf.reduce_min([shape[0], shape[1]])\n",
    "    top_crop = (shape[0] - min_dim) // 4\n",
    "    bottom_crop = shape[0] - top_crop\n",
    "    left_crop = (shape[1] - min_dim) // 4\n",
    "    right_crop = shape[1] - left_crop\n",
    "    return image[top_crop:bottom_crop, left_crop:right_crop]\n",
    "\n",
    "\n",
    "def preprocess(image, label, randomize=False):\n",
    "    if randomize:\n",
    "        cropped_image = random_crop(image)\n",
    "        cropped_image = tf.image.random_flip_left_right(cropped_image)\n",
    "    else:\n",
    "        cropped_image = central_crop(image)\n",
    "    resized_image = tf.image.resize(cropped_image, [224, 224])\n",
    "    final_image = keras.applications.xception.preprocess_input(resized_image)\n",
    "    return final_image, label\n",
    "\n",
    "batch_size = 32\n",
    "train_set = train_set_raw.shuffle(1000).repeat()\n",
    "train_set = train_set.map(partial(preprocess, randomize=True)).batch(batch_size).prefetch(1)\n",
    "valid_set = valid_set_raw.map(preprocess).batch(batch_size).prefetch(1)\n",
    "test_set = test_set_raw.map(preprocess).batch(batch_size).prefetch(1)\n",
    "\n",
    "images_resized = tf.image.resize(images, [224, 224])\n",
    "plot_color_image(images_resized[0])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def plot_image(image):\n",
    "    plt.imshow(image, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    \n",
    "def preprocess(image, label):\n",
    "    resized_image = tf.image.resize(image, [224, 224])\n",
    "    final_image = keras.applications.xception.preprocess_input(resized_image)\n",
    "    return final_image, label\n",
    "\n",
    "\n",
    "\n",
    "test_split, valid_split, train_split = tfds.Split.TRAIN.subsplit([10, 15, 75])\n",
    "\n",
    "test_set_raw = tfds.load(\"tf_flowers\", split=test_split, as_supervised=True)\n",
    "valid_set_raw = tfds.load(\"tf_flowers\", split=valid_split, as_supervised=True)\n",
    "train_set_raw = tfds.load(\"tf_flowers\", split=train_split, as_supervised=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = pandas.read_csv(\"./train.csv\")\n",
    "valid_df = pandas.read_csv(\"./valid.csv\")\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory='data/train',\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"class\",\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe=valid_df,\n",
    "        directory='data/validation',\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"class\",\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folderpath = df_clean.path\n",
    "#files = data_folderpath.to_list()\n",
    "filepaths = data_folderpath.to_list()\n",
    "len(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepaths = glob(glob_str)\n",
    "batch_size = 1024\n",
    "img_size = 224\n",
    "n_files = len(filepaths)\n",
    "cur_batch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    # drop last if it does not fit\n",
    "    if (n_files - cur_batch*batch_size) < batch_size or cur_batch == 0:\n",
    "        ids = np.random.randint(0, n_files, n_files)\n",
    "        np.random.shuffle(ids)\n",
    "        cur_batch = 0\n",
    "    train_data = []\n",
    "    for i in range(batch_size):\n",
    "        image_ab = load_image(filepaths[ids[cur_batch*batch_size+i]])\n",
    "        train_data.append([image_ab[:, :img_size], image_ab[:, img_size:]])\n",
    "\n",
    "    cur_batch = (cur_batch + 1) % int(len(filepaths)/batch_size)\n",
    "\n",
    "    train_data = np.array(train_data)\n",
    "#    yield train_data, cur_batch\n",
    "\n",
    "\n",
    "\n",
    "#data=ImageDataBunch.from_df(path=\"ut-zap50k-images-square/\",df=df_clean, size=224,bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folderpath = df_clean.path\n",
    "\n",
    "files = data_folderpath.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(files[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = create_minibatches(data_folderpath.to_list, 128, 224)\n",
    "#        data_folderpath + \"/train/*.jpg\", batch_size, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_data_iterator = iterate_minibatches(\n",
    "#         data_folderpath + \"/val/*.jpg\", n_checkpoint_samples, image_size)\n",
    "\n",
    "\n",
    "img_ab_fixed, _ = next(data_iterator)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator\n",
    "\n",
    "\n",
    "#al_data_iterator = iterate_minibatches(data_folderpath + \"/val/*.jpg\", n_checkpoint_samples, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "from keras.applications import imagenet_utils\n",
    "\n",
    "global pwidth\n",
    "global pheight\n",
    "global network_model\n",
    "\n",
    "pwidth = 224\n",
    "pheight = 224\n",
    "    \n",
    "global graph \n",
    "graph = tf.get_default_graph()\n",
    "network_model = MobileNetV2(weights = 'imagenet', include_top = False, input_shape = (pwidth,pheight,3),pooling = 'avg')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img_data = image.load_img(img_path, target_size=(pwidth, pheight))\n",
    "img_vector = image.img_to_array(img_data)\n",
    "img_vector = np.expand_dims(img_vector, axis=0)\n",
    "img_vector = preprocess_input(img_vector) #Problem here, must be convention of keras to pass by reference?\n",
    "img_vector = imagenet_utils.preprocess_input(img_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_features = network_model.predict(img_vector)\n",
    "\n",
    "#Get pandas df of n clo\n",
    "nn_index, neighbors_df = nearest_neighbor_image_finder(img_features, 100, database_df,0,100,100)\n",
    "neighbors = neighbors_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbor_image_finder(query_features, num_neighs, database, price_filt, min_price, max_price,): \n",
    "    ''' function to return nearest neighbors for a query\n",
    "    \n",
    "    Args: \n",
    "        query_features (array): numpy array of extracted image features\n",
    "        num_neighs (int): number of neighbors to return \n",
    "        datbase(df): pandas dataframe containing image database\n",
    "        fig_plot (bool): boolean to indicate of plotting is desired (1 for yes)\n",
    "        min_price (float): minimum budget\n",
    "        max_price (float): max budget\n",
    "        remove_dup (bool): remove image from database if it exists\n",
    "    \n",
    "    return: \n",
    "        nn_results: indices of nearest_neighbor lookup\n",
    "        neighbor_pd: pandas dataframe subsetted on returned values from knn search\n",
    "    '''\n",
    "    #########################################\n",
    "    ''' i don't actually want nearest neighbors.... maybe an average or latent images and the text.\n",
    "        should return text.\n",
    "    '''\n",
    "    # #############################################\n",
    "    #Filter Database based on given price range\n",
    "    if price_filt:\n",
    "        database  = database[(database['price']< max_price) & (database['price']> min_price)]\n",
    "    \n",
    "    #logic here in case the n exceeds number of items in database\n",
    "    size_filter_frame = database.shape[0]\n",
    "    num_neighs = min(num_neighs, size_filter_frame)\n",
    "    \n",
    "    #Fit Nearest Neighbor Model\n",
    "    database_features = np.vstack(database['image_features'])\n",
    "    neighs = NearestNeighbors(n_neighbors=num_neighs) \n",
    "    neighs.fit(database_features)\n",
    "    distance, nn_index = neighs.kneighbors(query_features, return_distance=True)\n",
    "\n",
    "    #Get nearest neighbor subset\n",
    "    neighbor_pd = []\n",
    "    for row in nn_index: \n",
    "        neighbor_pd.append(database.iloc[row])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_iterator = iterate_minibatches(data\n",
    "#         data_folderpath + \"/train/*.jpg\", batch_size, image_size)\n",
    "# val_data_iterator = iterate_minibatches(\n",
    "#         data_folderpath + \"/val/*.jpg\", n_checkpoint_samples, image_size)\n",
    "\n",
    "img_ab_fixed, _ = next(val_data_iterator)\n",
    "# img_a_fixed, img_b_fixed = img_ab_fixed[:, 0], img_ab_fixed[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ones = np.ones((batch_size, ) + disc_patch, dtype=np.float32)\n",
    "    zeros = np.zeros((batch_size, ) + disc_patch, dtype=np.float32)\n",
    "    dummy = zeros\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        D.trainable = True\n",
    "        G.trainable = False\n",
    "\n",
    "        image_ab_batch, _ = next(data_iterator)\n",
    "        loss_d = D_model.train_on_batch(\n",
    "            [image_ab_batch[:, 0], image_ab_batch[:, 1]],\n",
    "            [ones, zeros])\n",
    "\n",
    "        D.trainable = False\n",
    "        G.trainable = True\n",
    "        image_ab_batch, _ = next(data_iterator)\n",
    "        loss_g = G_model.train_on_batch(\n",
    "            [image_ab_batch[:, 0], image_ab_batch[:, 1]],\n",
    "            [ones, dummy])\n",
    "\n",
    "        print(\"iter\", i)\n",
    "        if (i % iters_per_checkpoint) == 0:\n",
    "            G.trainable = False\n",
    "            fake_image = G.predict(img_a_fixed)\n",
    "            log_images(fake_image, 'val_fake', i, logger)\n",
    "            save_model(G, out_dir)\n",
    "\n",
    "        log_losses(loss_d, loss_g, i, logger)\n",
    "\n",
    "        \n",
    "\n",
    "# #n = 12856 images\n",
    "# # images are \"path\"\n",
    "\n",
    "# # now need to split into test train for sci-kit learn\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "# ...     X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "dataframe = df_clean #pandas.read_csv(\"INPUTFILE.csv\", skiprows=range(0, 0))\n",
    "\n",
    "dataset = dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,0:50].astype(float) # number of cols-1\n",
    "Y = dataset[:,50]\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "encoded_Y = np_utils.to_categorical(encoded_Y)\n",
    "print(\"encoded_Y=\", encoded_Y) \n",
    "# baseline model\n",
    "def create_baseline():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(5, input_dim=5, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(5, kernel_initializer='normal', activation='relu'))\n",
    "    #model.add(Dense(2, kernel_initializer='normal', activation='sigmoid'))\n",
    "\n",
    "    model.add(Dense(2, kernel_initializer='normal', activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  # for binayr classification\n",
    "        #model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # for multi class\n",
    "    return model\n",
    "\n",
    "\n",
    "model=create_baseline();\n",
    "history=model.fit(X, encoded_Y, batch_size=50, nb_epoch=500, validation_split = 0.2, verbose=1)\n",
    "\n",
    "print(history.history.keys())\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "pre_cls=model.predict_classes(X)    \n",
    "cm1 = confusion_matrix(encoder.transform(Y),pre_cls)\n",
    "print('Confusion Matrix : \\n')\n",
    "print(cm1)\n",
    "\n",
    "\n",
    "score, acc = model.evaluate(X,encoded_Y)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow2_p36] *",
   "language": "python",
   "name": "conda-env-tensorflow2_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "523.975px",
    "left": "1161.26px",
    "right": "20px",
    "top": "120px",
    "width": "688.223px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
