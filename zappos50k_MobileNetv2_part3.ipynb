{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://vision.cs.utexas.edu/projects/finegrained/utzap50k/ut-zap50k-images-square.zip!wget http://vision.cs.utexas.edu/projects/finegrained/utzap50k/ut-zap50k-data.zip\n",
    "# !unzip ut-zap50k-images-square.zip\n",
    "# !unzip ut-zap50k-data.zip\n",
    "\n",
    "#Importing the required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "#from tqdm import tqdm_notebook\n",
    "import os\n",
    "from glob import glob\n",
    "from os.path import isdir,abspath,join\n",
    "from os import listdir\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from datetime import datetime\n",
    "today = datetime.today()\n",
    "\n",
    "df_filename = './summary_Feb-02-2020.pkl'\n",
    "#df = pd.read_pickle(df_filename)\n",
    "\n",
    "json_summary_file = f'./summary_Feb-02-2020.json'\n",
    "#df = pd.read_json(json_summary_file)\n",
    "\n",
    "summary_file ='summary_withFeatures_Feb-02-2020.pkl'\n",
    "#\n",
    "df = pd.read_pickle(summary_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simplify data set to only include shoes and boots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['Gender']=='Men;Boys;Women;Girls')  # ignore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'Sneakers'] = df['SubCategory.Sneakers.and.Athletic.Shoes'] == 1\n",
    "df.loc[:,'Boots'] = (df.Category1 == 'Boots')\n",
    "df.loc[:,'Shoes'] = (df.Category1 == 'Shoes') & (~df.Sneakers)#remove \n",
    "############\n",
    "#remove ([ 'Boys',  'Boys;Girls', 'Girls','Women;Girls', 'Men;Boys;Women;Girls', nan\n",
    "mens =  df['Gender'] == 'Men'       \n",
    "womens =  df['Gender'] == 'Women' \n",
    "etc =  df['Gender'] =='Men;Women' \n",
    "df.loc[:, 'Adult'] = mens | womens | etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split shoes into athletic and \"other\"\n",
    "## remove kids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make some expository columns \n",
    "#keep Adult, Sneakers, Boots, Shoes\n",
    "\n",
    "keep_rows = (df.Sneakers | df.Boots | df.Shoes) & (df.Adult)\n",
    "\n",
    "keep_columns = ['CID',\n",
    "                 'Category',\n",
    "                 'SubCategory',\n",
    "                 'Gender',\n",
    "                 'path',\n",
    "                 'Sneakers',\n",
    "                 'Boots',\n",
    "                 'Shoes',\n",
    "                 'path_and_file',\n",
    "                 'Brand',\n",
    "                 'Filename',\n",
    "                 'image_features']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = df.loc[keep_rows,keep_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the simple file\n",
    "summary_file ='categories_with_features_Feb-05-2020.pkl'\n",
    "df.to_pickle(summary_file)\n",
    "\n",
    "summary_file ='categories_with_features_Feb-05-2020.json'\n",
    "df.to_json(summary_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               [Shoes, Oxfords, Bostonian, 100627.72.jpg]\n",
       "1              [Shoes, Oxfords, Bostonian, 100627.255.jpg]\n",
       "2               [Shoes, Oxfords, Bostonian, 100657.72.jpg]\n",
       "3              [Shoes, Oxfords, Bostonian, 100657.216.jpg]\n",
       "4                 [Boots, Mid-Calf, Durango, 101026.3.jpg]\n",
       "                               ...                        \n",
       "50020            [Shoes, Heels, J. Renee, 8168300.128.jpg]\n",
       "50021            [Shoes, Heels, J. Renee, 8168300.742.jpg]\n",
       "50022          [Shoes, Heels, J. Renee, 8168300.57113.jpg]\n",
       "50023         [Shoes, Heels, J. Renee, 8168300.384413.jpg]\n",
       "50024    [Shoes, Sneakers and Athletic Shoes, Travis Ma...\n",
       "Name: path_and_file, Length: 34278, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.path_and_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'CategoryDir'] = 'Shoes'\n",
    "df.loc[df.Boots==1,'CategoryDir'] = 'Boots'\n",
    "df.loc[df.Sneakers==1,'CategoryDir'] = 'Sneakers'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I have my three categories.. lets grab the images and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ergonyc/Projects/Insight/UTzappos50k\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0             100627.72.jpg\n",
       "1            100627.255.jpg\n",
       "2             100657.72.jpg\n",
       "3            100657.216.jpg\n",
       "4              101026.3.jpg\n",
       "                ...        \n",
       "50020       8168300.128.jpg\n",
       "50021       8168300.742.jpg\n",
       "50022     8168300.57113.jpg\n",
       "50023    8168300.384413.jpg\n",
       "50024      8169712.2557.jpg\n",
       "Name: Filename, Length: 34278, dtype: object"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "\n",
    "\n",
    "df['Filename']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into 76% train (12% validation), 12% test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import iglob\n",
    "from os.path import join,basename\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "data_path = './sneaks/data/' # path of the data\n",
    "train_path = './train'\n",
    "test_path = './test'\n",
    "ldata_path = './data'\n",
    "val_path = './validate'\n",
    "\n",
    "df.loc[:,'train'] = 1\n",
    "df.loc[:,'test'] = 0 \n",
    "df.loc[:,'validate'] = 0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [Shoes, Oxfords, Bostonian, 100627.72.jpg]\n",
       "1    [Shoes, Oxfords, Bostonian, 100627.255.jpg]\n",
       "2     [Shoes, Oxfords, Bostonian, 100657.72.jpg]\n",
       "3    [Shoes, Oxfords, Bostonian, 100657.216.jpg]\n",
       "4       [Boots, Mid-Calf, Durango, 101026.3.jpg]\n",
       "Name: path_and_file, dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## cat = df['path_and_file']\n",
    "\n",
    "df.path_and_file.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for file in iglob(join(data_path,'*')):\n",
    "#for file( in iglob(join(train_path,'*')):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(ldata_path):\n",
    "\n",
    "\n",
    "    # create full set\n",
    "    print('_'*30)\n",
    "    print('Creating full local category set....')\n",
    "    print('_'*30)\n",
    "\n",
    "\n",
    "    for idx in df.index:\n",
    "        save_path = join(ldata_path,df.loc[idx,'CategoryDir'])\n",
    "\n",
    "        #print(save_path)\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        img =  join(data_path,df.loc[idx,'path'])\n",
    "        #print(img)\n",
    "        shutil.copy2(img,save_path)\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________\n",
      "Creating full train set....\n",
      "______________________________\n"
     ]
    }
   ],
   "source": [
    "# create test set\n",
    "print('_'*30)\n",
    "print('Creating full train set....')\n",
    "print('_'*30)\n",
    "\n",
    "for idx in df.index:\n",
    "    save_path = join(train_path,df.loc[idx,'CategoryDir'])\n",
    "    #print(save_path)\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    img =  join(data_path,df.loc[idx,'path'])\n",
    "    #print(img)\n",
    "    shutil.copy2(img,save_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________\n",
      "Creating test set....\n",
      "______________________________\n",
      "2264.16\n",
      "3469.68\n",
      "2492.88\n"
     ]
    }
   ],
   "source": [
    "# create test set\n",
    "print('_'*30)\n",
    "print('Creating test set....')\n",
    "print('_'*30)\n",
    "\n",
    "#instead of looking at the files, lets just use the database\n",
    "\n",
    "for file in iglob(join(train_path,'*')):\n",
    "#for file in df.path:\n",
    "    save_path = join(test_path, basename(file))\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    total_imgs = [x for x in iglob(join(file,'*'))]\n",
    "\n",
    "    rand_amt = 2* 0.12 * len(total_imgs)  # select 24% of data from each category as testing + validation set\n",
    "    print(rand_amt)\n",
    "    test_imgs= []\n",
    "    for i in range(int(rand_amt)):\n",
    "        img = random.choice(total_imgs)\n",
    "        if img not in test_imgs:\n",
    "            #print(img)\n",
    "            df.loc[df.Filename == basename(img),'train'] = 0\n",
    "            df.loc[df.Filename == basename(img),'test'] = 1\n",
    "            shutil.move(img,save_path)\n",
    "            test_imgs.append(img)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________\n",
      "Creating validation set....\n",
      "______________________________\n",
      "1019.0\n",
      "1538.5\n",
      "1101.5\n"
     ]
    }
   ],
   "source": [
    "# create validation set\n",
    "print('_'*30)\n",
    "print('Creating validation set....')\n",
    "print('_'*30)\n",
    "\n",
    "#instead of looking at the files, lets just use the database\n",
    "for file in iglob(join(test_path,'*')):\n",
    "#for file in df.path:\n",
    "    save_path = join(val_path, basename(file))\n",
    "\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    total_imgs = [x for x in iglob(join(file,'*'))]\n",
    "\n",
    "    rand_amt = 0.5 * len(total_imgs)  # select 50% of data from each category to split evenly between test and validation\n",
    "    print(rand_amt)\n",
    "    test_imgs= []\n",
    "    for i in range(int(rand_amt)):\n",
    "        img = random.choice(total_imgs)\n",
    "        if img not in test_imgs:\n",
    "            #print(img)\n",
    "            df.loc[df.Filename == basename(img),'test'] = 0\n",
    "            df.loc[df.Filename == basename(img),'validation'] = 1\n",
    "            shutil.move(img,save_path)\n",
    "            test_imgs.append(img)\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "# # create valisation set\n",
    "# print('_'*30)\n",
    "# print('Creating validation set....')\n",
    "# print('_'*30)\n",
    "      \n",
    "# #instead of looking at the files, lets just use the database\n",
    "# for file in iglob(join(train_path,'*')):\n",
    "#             #for file in df.path:\n",
    "#     save_path = join(val_path, basename(file))\n",
    "\n",
    "#     if not os.path.exists(save_path):\n",
    "#         os.makedirs(save_path)\n",
    "    \n",
    "#     total_imgs = [x for x in iglob(join(file,'*'))]\n",
    "\n",
    "#     rand_amt = 0.12 * len(total_imgs)  # select 12% of data from each category as testing set\n",
    "#     print(rand_amt)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # save the simple file\n",
    "# summary_file ='train_test_Feb-05-2020.pkl'\n",
    "# df.to_pickle(summary_file)\n",
    "\n",
    "# summary_file ='train_test_Feb-05-2020.json'\n",
    "# df.to_json(summary_file)\n",
    "\n",
    "# save the simple file\n",
    "summary_file ='train_test_val_Feb-06-2020.pkl'\n",
    "df.to_pickle(summary_file)\n",
    "\n",
    "summary_file ='train_test_val_Feb-06-2020.json'\n",
    "df.to_json(summary_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31218"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chg.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14       0\n",
       "15       0\n",
       "16       0\n",
       "17       0\n",
       "20       0\n",
       "        ..\n",
       "49990    0\n",
       "49996    0\n",
       "49997    1\n",
       "49998    0\n",
       "50009    0\n",
       "Name: test, Length: 7339, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.train==0].test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pandas dataframe and plot... \n",
    "\n",
    "\n",
    "# Get label frequencies in descending order\n",
    "label_freq = movies['Genre'].apply(lambda s: str(s).split('|')).explode().value_counts().sort_values(ascending=False)\n",
    "\n",
    "# Bar plot\n",
    "style.use(\"fivethirtyeight\")\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.barplot(y=label_freq.index.values, x=label_freq, order=label_freq.index)\n",
    "plt.title(\"Label frequency\", fontsize=14)\n",
    "plt.xlabel(\"\")\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://vision.cs.utexas.edu/projects/finegrained/utzap50k/ut-zap50k-images-square.zip!wget http://vision.cs.utexas.edu/projects/finegrained/utzap50k/ut-zap50k-data.zip\n",
    "# !unzip ut-zap50k-images-square.zip\n",
    "# !unzip ut-zap50k-data.zip\n",
    "\n",
    "#Importing the required libraries\n",
    "\n",
    "\n",
    "#import numpy as np\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler,EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# from keras.preprocessing import image\n",
    "# from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "#from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "# from keras.applications import imagenet_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import io\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import h5py\n",
    "from keras.models import model_from_json\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "def load_model(folder_path):\n",
    "    # load json and create model\n",
    "    json_file = open(\"{}/model.json\".format(folder_path), 'r')\n",
    "    model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(model_json)\n",
    "    # load weights into new model\n",
    "    model.load_weights(\"{}/model.h5\".format(folder_path))\n",
    "    print(\"Loaded model from disk\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def save_model(model, folder_path):\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(\"{}/model.json\".format(folder_path), \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"{}/model.h5\".format(folder_path))\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "\n",
    "def load_image(filepath, scale=True):\n",
    "    images = np.array(Image.open(filepath), dtype=int)\n",
    "    if scale:\n",
    "        images = 2 * (images / 255.0) - 1\n",
    "        images = images.astype(float)\n",
    "    return images\n",
    "\n",
    "\n",
    "def iterate_minibatches(glob_str, batch_size=128, img_size=256):\n",
    "    filepaths = glob(glob_str)\n",
    "    n_files = len(filepaths)\n",
    "    cur_batch = 0\n",
    "    while True:\n",
    "        # drop last if it does not fit\n",
    "        if (n_files - cur_batch*batch_size) < batch_size or cur_batch == 0:\n",
    "            ids = np.random.randint(0, n_files, n_files)\n",
    "            np.random.shuffle(ids)\n",
    "            cur_batch = 0\n",
    "\n",
    "        train_data = []\n",
    "        for i in range(batch_size):\n",
    "            image_ab = load_image(filepaths[ids[cur_batch*batch_size+i]])\n",
    "            train_data.append([image_ab[:, :img_size], image_ab[:, img_size:]])\n",
    "\n",
    "        cur_batch = (cur_batch + 1) % int(len(filepaths)/batch_size)\n",
    "\n",
    "        train_data = np.array(train_data)\n",
    "        yield train_data, cur_batch\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "database = df\n",
    "size_filter_frame = database.shape[0]\n",
    "num_neighs = 10\n",
    "\n",
    "\n",
    "features = database['image_features_x']\n",
    "features[10]\n",
    "\n",
    "query_features = (features[10])\n",
    "\n",
    "#Fit Nearest Neighbor Model\n",
    "database_features = np.vstack(database['image_features_x'])\n",
    "\n",
    "neighs = NearestNeighbors(n_neighbors=num_neighs) \n",
    "neighs.fit(database_features)\n",
    "\n",
    "print(query_features.shape)\n",
    "query2 =query_features.reshape(1,-1)\n",
    "print(query2.shape)\n",
    "\n",
    "distance, nn_index = neighs.kneighbors(query_features.reshape(1,-1), return_distance=True)\n",
    "    \n",
    "    \n",
    "\n",
    "nn_index\n",
    "nn_index.tolist()[0]\n",
    "\n",
    "#Get nearest neighbor subset\n",
    "neighbors = \n",
    "neighbor_pd = []\n",
    "neighbor_pd = df.iloc[0]\n",
    "for row in range(1,10): \n",
    "    neighbor_pd.concat(df.iloc[row])\n",
    "\n",
    "    \n",
    "\n",
    "neighbor_pd = database.iloc[nn_index.tolist()[0]]\n",
    "neighbor_pd.shape\n",
    "\n",
    "    \n",
    "size_filter_frame = database.shape[0]\n",
    "num_neighs = min(num_neighs, size_filter_frame)\n",
    "\n",
    "#Fit Nearest Neighbor Model\n",
    "database_features = np.vstack(df['image_features'])\n",
    "neighs = NearestNeighbors(n_neighbors=num_neighs+1) #add plus one in case image exists in database\n",
    "neighs.fit(database_features)\n",
    "distance, nn_index = neighs.kneighbors(query_features, return_distance=True)\n",
    "\n",
    "    #Check to see if image is already in dabase and remove (see if distance == 0)\n",
    "    #If True, remove n = 0, and take n+1 neighbor\n",
    "    if remove_dup: \n",
    "        updated_nn_index = []\n",
    "        for i,row in enumerate(distance):\n",
    "            image_exists = len(nn_index[i, row!=0]) == num_neighs\n",
    "            if image_exists: \n",
    "                new_in= nn_index[i,1:num_neighs+1]\n",
    "            else: \n",
    "                new_in = nn_index[i,0:num_neighs]\n",
    "        \n",
    "            updated_nn_index.append(new_in)\n",
    "    \n",
    "        nn_index = np.array(updated_nn_index)\n",
    "    \n",
    "    #Get pandas dataframes\n",
    "    panda_list = []\n",
    "    for row in nn_index: \n",
    "        panda_list.append(price_filter_df.iloc[row])\n",
    "    \n",
    "    #Get nearest neighbor result urls \n",
    "    url_matrix = []\n",
    "    for row in nn_index: \n",
    "        url_row = price_filter_df['image_url'].values[row]\n",
    "        url_matrix.append(url_row)\n",
    "    \n",
    "    url_matrix = np.array(url_matrix)\n",
    "\n",
    "    #concat query image array to result arrays \n",
    "    images_urls = np.concatenate([query_image, url_matrix], axis = 1)\n",
    "\n",
    "    if fig_plot: \n",
    "        get_fig_plots(images_urls)\n",
    "\n",
    "    return(nn_index, images_urls, panda_list)  \n",
    "\n",
    "pwidth = 224\n",
    "pheight = 224 #\n",
    "\n",
    "\n",
    "## train and test generator\n",
    "#train_gen, val_gen = train_val_generator(batch_size, train_path, test_path)\n",
    "\n",
    "# #from utils import train_val_generator\n",
    "data_path = './data/'       # path of the data\n",
    "train_path = './train'      \n",
    "test_path = './test'        \n",
    "\n",
    "TARGET_SZ = 224\n",
    "\n",
    "input_shape = (TARGET_SZ,TARGET_SZ,3) #(img_width,i mg_height,img_channel)')\n",
    "#batch_size = 32\n",
    "\n",
    "cnn_model = MobileNetV2(weights = 'imagenet', \n",
    "                            include_top = False, \n",
    "                            input_shape = input_shape, \n",
    "                            pooling = 'avg')\n",
    "\n",
    "model_name = 'MobileNetV2'\n",
    "# with graph.as_default():\n",
    "#     img_features = network_model.predict(img_vector)\n",
    "cnn_model.summary()\n",
    "\n",
    "df.loc[:,['Category.Boots','Category.Sandals','Category.Shoes','Category.Slippers']]\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "%matplotlib inline\n",
    "\n",
    "#Start assessing models. Try a family of models to identify the best performers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "#from tqdm import tqdm_notebook\n",
    "import os\n",
    "from glob import glob\n",
    "from os.path import isdir,abspath,join\n",
    "from os import listdir\n",
    "\n",
    "\n",
    "#import numpy as np\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler,EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# from keras.preprocessing import image\n",
    "# from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "#from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "# from keras.applications import imagenet_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "today = datetime.today()\n",
    "\n",
    "\n",
    "df_filename = './summary_Jan-29-2020.pkl'\n",
    "#df = pd.read_pickle(df_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.getcwd()\n",
    "os.chdir('sneaks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_summary_file = f'./summary_Jan-29-2020.json'\n",
    "#df = pd.read_json(json_summary_file)\n",
    "\n",
    "summary_file ='summary_withFeatures_Jan-29-2020.pkl'\n",
    "#\n",
    "df = pd.read_pickle(summary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_base = '/home/ergonyc/Projects/Insight/UTzappos50k/sneaks'\n",
    "database_path = db_base + '/'+ 'summary_Jan-29-2020_processed.json'\n",
    "database_json = json.load(open(database_path))\n",
    "database_df = pd.DataFrame(database_json)\n",
    "\n",
    "#df2= df.rename(columns={'image_features':'image_features_y'})\n",
    "\n",
    "# COMBINE meta_data and categories.  then iterate over all files to get vector\n",
    "\n",
    "#df['image_features']=df['image_features_x'].copy()  # freaking renaming didn't work!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "database = df\n",
    "size_filter_frame = database.shape[0]\n",
    "num_neighs = 10\n",
    "\n",
    "\n",
    "features = database['image_features_x']\n",
    "features[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_features = (features[10])\n",
    "\n",
    "#Fit Nearest Neighbor Model\n",
    "database_features = np.vstack(database['image_features_x'])\n",
    "\n",
    "neighs = NearestNeighbors(n_neighbors=num_neighs) \n",
    "neighs.fit(database_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query_features.shape)\n",
    "query2 =query_features.reshape(1,-1)\n",
    "print(query2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance, nn_index = neighs.kneighbors(query_features.reshape(1,-1), return_distance=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_index\n",
    "nn_index.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get nearest neighbor subset\n",
    "neighbors = \n",
    "neighbor_pd = []\n",
    "neighbor_pd = df.iloc[0]\n",
    "for row in range(1,10): \n",
    "    neighbor_pd.concat(df.iloc[row])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_pd = database.iloc[nn_index.tolist()[0]]\n",
    "neighbor_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "size_filter_frame = database.shape[0]\n",
    "num_neighs = min(num_neighs, size_filter_frame)\n",
    "\n",
    "#Fit Nearest Neighbor Model\n",
    "database_features = np.vstack(df['image_features'])\n",
    "neighs = NearestNeighbors(n_neighbors=num_neighs+1) #add plus one in case image exists in database\n",
    "neighs.fit(database_features)\n",
    "distance, nn_index = neighs.kneighbors(query_features, return_distance=True)\n",
    "\n",
    "    #Check to see if image is already in dabase and remove (see if distance == 0)\n",
    "    #If True, remove n = 0, and take n+1 neighbor\n",
    "    if remove_dup: \n",
    "        updated_nn_index = []\n",
    "        for i,row in enumerate(distance):\n",
    "            image_exists = len(nn_index[i, row!=0]) == num_neighs\n",
    "            if image_exists: \n",
    "                new_in= nn_index[i,1:num_neighs+1]\n",
    "            else: \n",
    "                new_in = nn_index[i,0:num_neighs]\n",
    "        \n",
    "            updated_nn_index.append(new_in)\n",
    "    \n",
    "        nn_index = np.array(updated_nn_index)\n",
    "    \n",
    "    #Get pandas dataframes\n",
    "    panda_list = []\n",
    "    for row in nn_index: \n",
    "        panda_list.append(price_filter_df.iloc[row])\n",
    "    \n",
    "    #Get nearest neighbor result urls \n",
    "    url_matrix = []\n",
    "    for row in nn_index: \n",
    "        url_row = price_filter_df['image_url'].values[row]\n",
    "        url_matrix.append(url_row)\n",
    "    \n",
    "    url_matrix = np.array(url_matrix)\n",
    "\n",
    "    #concat query image array to result arrays \n",
    "    images_urls = np.concatenate([query_image, url_matrix], axis = 1)\n",
    "\n",
    "    if fig_plot: \n",
    "        get_fig_plots(images_urls)\n",
    "\n",
    "    return(nn_index, images_urls, panda_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwidth = 224\n",
    "pheight = 224 #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train and test generator\n",
    "#train_gen, val_gen = train_val_generator(batch_size, train_path, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #from utils import train_val_generator\n",
    "data_path = './data/' # path of the data\n",
    "train_path = './train'\n",
    "test_path = './test'\n",
    "\n",
    "TARGET_SZ = 224\n",
    "\n",
    "input_shape = (TARGET_SZ,TARGET_SZ,3) #(img_width,i mg_height,img_channel)')\n",
    "#batch_size = 32\n",
    "\n",
    "cnn_model = MobileNetV2(weights = 'imagenet', \n",
    "                            include_top = False, \n",
    "                            input_shape = input_shape, \n",
    "                            pooling = 'avg')\n",
    "\n",
    "model_name = 'MobileNetV2'\n",
    "# with graph.as_default():\n",
    "#     img_features = network_model.predict(img_vector)\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,['Category.Boots','Category.Sandals','Category.Shoes','Category.Slippers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "%matplotlib inline\n",
    "\n",
    "#Start assessing models. Try a family of models to identify the best performers \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BINARY ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BINARY ENCODER Shoes or Not\n",
    "\n",
    "# start by predicting shoes versus \"other\"\n",
    "labels = pd.DataFrame(df['Category.Shoes'])\n",
    "\n",
    "#Combine Data, get test/train split \n",
    "image_features = pd.DataFrame((df['image_features']))\n",
    "\n",
    "X_train_pd, X_test_pd, Y_train_pd, Y_test_pd = train_test_split(image_features, \n",
    "                                                                labels, \n",
    "                                                                test_size = 0.3, \n",
    "                                                                random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vstack(X_train_pd['image_features'])\n",
    "X_test  = np.vstack(X_test_pd['image_features'])\n",
    "Y_train = Y_train_pd.values.flatten()\n",
    "Y_test  = Y_test_pd.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate diffent classifier types\n",
    "clf_logit = LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter = 1200)\n",
    "ridge_model = RidgeClassifier(max_iter = 1000)\n",
    "\n",
    "neighbors = [1,3,5]\n",
    "knn_models = [KNeighborsClassifier(n_neighbors=num) for num in neighbors]\n",
    "\n",
    "n_estimators = [10,100,500]\n",
    "forest_model = RandomForestClassifier(n_estimators=500, )\n",
    "\n",
    "models = [clf_logit, ridge_model, knn_models[0], knn_models[1], knn_models[2], forest_model]\n",
    "model_names = ['logistic','ridge', 'knn_1', 'knn_3', 'knn_5', 'forest_model']\n",
    "\n",
    "\n",
    "#Determine Model Scores\n",
    "avg_scores = []\n",
    "std_scores = []\n",
    "for clf, name in zip(models, model_names): \n",
    "    print('training: ', name, ' model')\n",
    "    scores = cross_val_score(clf, X_train, Y_train, cv = 5)\n",
    "    avg_scores.append(np.mean(scores))\n",
    "    std_scores.append(np.std(scores))\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_scores)\n",
    "print(std_scores)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Model Results \n",
    "plt.bar(model_names, avg_scores,yerr = std_scores)\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('Classifier_Comparison.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine tune Log model\n",
    "import math\n",
    "alpha = [0.1, 1,10]\n",
    "log_avg = []\n",
    "log_std = []\n",
    "for a in alpha: \n",
    "    print('log model with C =', a)\n",
    "    clf_log = LogisticRegression(C=a, multi_class='ovr', solver='lbfgs', max_iter=2000)\n",
    "    scores_ridge = cross_val_score(clf_log, X_train, Y_train, cv = 5)\n",
    "    log_avg.append(np.mean(scores_ridge))\n",
    "    log_std.append(np.std(scores_ridge))\n",
    "\n",
    "print(log_avg)\n",
    "print(log_std)\n",
    "\n",
    "\n",
    "#Plot Model Results \n",
    "plt.bar(alpha, log_avg,yerr = log_std)\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('Classifier_Comparison.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from seaborn import heatmap\n",
    "\n",
    "\n",
    "#Display Confusion Matrix\n",
    "X_test = np.vstack(X_test_pd['image_features'])\n",
    "\n",
    "clf_log = LogisticRegression(C = 1, multi_class='ovr', max_iter=2000, solver='lbfgs')\n",
    "clf_log.fit(X_train, Y_train)\n",
    "log_score = clf_log.score(X_test, Y_test)\n",
    "log_ypred = clf_log.predict(X_test)\n",
    "log_confusion_matrix = confusion_matrix(Y_test, log_ypred)\n",
    "print(log_confusion_matrix)\n",
    "\n",
    "heatmap(log_confusion_matrix, annot=True, linewidths=0.5, cmap='Blues')\n",
    "plt.savefig('log_Matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "#See where classifiers are messing up \n",
    "panda_ints = Y_test_pd.index.values\n",
    "class_labels = [0,1]\n",
    "\n",
    "performance_matrix = []\n",
    "for row in class_labels: \n",
    "    bool_truth = (Y_test == row) \n",
    "    for column in class_labels: \n",
    "        bool_pred = (log_ypred==column)\n",
    "        performance_logical = np.logical_and(bool_truth, bool_pred)\n",
    "        performance_ints = panda_ints[performance_logical==True]\n",
    "        performance_matrix.append(performance_ints)\n",
    "        \n",
    "for num, entry in enumerate(performance_matrix): \n",
    "    plt.subplot(2,2,num +1)\n",
    "    rand_int = random.randint(0,len(entry)-1)\n",
    "    index = entry[rand_int]\n",
    "    path = data_path+df['path'][index]\n",
    "    img_data = image.load_img(path, target_size=(224, 224))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img_data);    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "#Save Trained model to disk\n",
    "filename = f'log_model_{today:%b-%d-%Y}.sav'\n",
    "joblib.dump(clf_log, filename)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CATEGORICAL LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### now do the test in 4 categories\n",
    "\n",
    "labels = df.loc[:,['Category.Boots','Category.Sandals','Category.Shoes','Category.Slippers']]\n",
    "\n",
    "X_train_pd, X_test_pd, Y_train_pd, Y_test_pd = train_test_split(image_features, \n",
    "                                                                labels, \n",
    "                                                                test_size = 0.3, \n",
    "                                                                random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pd.values\n",
    "\n",
    "X_train = np.vstack(X_train_pd['image_features'])\n",
    "X_test  = np.vstack(X_test_pd['image_features'])\n",
    "Y_train = Y_train_pd.values.flatten()\n",
    "Y_test  = Y_test_pd.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate diffent classifier types\n",
    "clf_logit = LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter = 1000)\n",
    "ridge_model = RidgeClassifier(max_iter = 1000)\n",
    "\n",
    "neighbors = [1,3,5]\n",
    "knn_models = [KNeighborsClassifier(n_neighbors=num) for num in neighbors]\n",
    "\n",
    "n_estimators = [10,100,500]\n",
    "forest_model = RandomForestClassifier(n_estimators=500, )\n",
    "\n",
    "models = [clf_logit, ridge_model, knn_models[0], knn_models[1], knn_models[2], forest_model]\n",
    "model_names = ['logistic','ridge', 'knn_1', 'knn_3', 'knn_5', 'forest_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine Model Scores\n",
    "avg_scores = []\n",
    "std_scores = []\n",
    "for clf, name in zip(models, model_names): \n",
    "    print('training: ', name, ' model')\n",
    "    scores = cross_val_score(clf, X_train, Y_train, cv = 5)\n",
    "    avg_scores.append(np.mean(scores))\n",
    "    std_scores.append(np.std(scores))\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_scores)\n",
    "print(std_scores)\n",
    " \n",
    "\n",
    "#Plot Model Results \n",
    "plt.bar(model_names, avg_scores,yerr = std_scores)\n",
    "plt.xlabel('Classifier')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('Classifier_Comparison.png')\n",
    "\n",
    "#Fine tune Log model\n",
    "import math\n",
    "alpha = [0.1, 1,10]\n",
    "log_avg = []\n",
    "log_std = []\n",
    "for a in alpha: \n",
    "    print('log model with C =', a)\n",
    "    clf_log = LogisticRegression(C=a, multi_class='ovr', solver='lbfgs', max_iter=2000)\n",
    "    scores_ridge = cross_val_score(clf_log, X_train, Y_train, cv = 5)\n",
    "    log_avg.append(np.mean(scores_ridge))\n",
    "    log_std.append(np.std(scores_ridge))\n",
    "\n",
    "print(log_avg)\n",
    "print(log_std)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from seaborn import heatmap\n",
    "\n",
    "\n",
    "#Display Confusion Matrix\n",
    "X_test = np.vstack(X_test_pd['image_features'])\n",
    "\n",
    "clf_log = LogisticRegression(C = 1, multi_class='ovr', max_iter=2000, solver='lbfgs')\n",
    "clf_log.fit(X_train, Y_train)\n",
    "log_score = clf_log.score(X_test, Y_test)\n",
    "log_ypred = clf_log.predict(X_test)\n",
    "log_confusion_matrix = confusion_matrix(Y_test, log_ypred)\n",
    "print(log_confusion_matrix)\n",
    "\n",
    "heatmap(log_confusion_matrix, annot=True, linewidths=0.5, cmap='Blues')\n",
    "plt.savefig('log_Matrix.png')\n",
    "\n",
    "import random\n",
    "\n",
    "#See where classifiers are messing up \n",
    "panda_ints = Y_test_pd.index.values\n",
    "class_labels = [0,1,2]\n",
    "\n",
    "performance_matrix = []\n",
    "for row in class_labels: \n",
    "    bool_truth = (Y_test == row) \n",
    "    for column in class_labels: \n",
    "        bool_pred = (log_ypred==column)\n",
    "        performance_logical = np.logical_and(bool_truth, bool_pred)\n",
    "        performance_ints = panda_ints[performance_logical==True]\n",
    "        performance_matrix.append(performance_ints)\n",
    "        \n",
    "for num, entry in enumerate(performance_matrix): \n",
    "    plt.subplot(3,3,num +1)\n",
    "    rand_int = random.randint(0,len(entry)-1)\n",
    "    index = entry[rand_int]\n",
    "    path = all_dataframes['image_file_path'][index]\n",
    "    img_data = image.load_img(path, target_size=(224, 224))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img_data);    \n",
    "    \n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "#Save Trained model to disk\n",
    "filename = f'log_model_{today:%d-%d-%2190621.sav'\n",
    "joblib.dump(clf_log, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random \n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "def nearest_neighbor_image_finder(query_image, query_features, num_neighs, database, fig_plot): \n",
    "    ''' function to return nearest neighbors for a query\n",
    "    \n",
    "    Args: \n",
    "        query_image (image): image \n",
    "        query_features (array): numpy array of extracted image features\n",
    "        num_neighs (int): number of neighbors to return \n",
    "        datbase(df): pandas dataframe containing image database\n",
    "        fig_plot (bool): boolean to indicate of plotting is desired (1 for yes)\n",
    "        #min_price (float): minimum budget\n",
    "        #max_price (float): max budget\n",
    "        #remove_dup (bool): remove image from database if it exists\n",
    "    \n",
    "    return: \n",
    "        nn_results (arr): indices of nearest_neighbor lookup\n",
    "        images_urls (arr): array of image urls for query and nearest neighbors sorted in nearest neighbor order\n",
    "        pandas_list (pd): pandas dataframe containing all relevant information of neighbors \n",
    "    '''\n",
    "    \n",
    "    remove_dup = True\n",
    "    \n",
    "    #logic here in case the n exceeds number of items in database\n",
    "    size_filter_frame = database.shape[0]\n",
    "    num_neighs = min(num_neighs, size_filter_frame)\n",
    "    \n",
    "    #Fit Nearest Neighbor Model\n",
    "    database_features = np.vstack(database['image_features'])\n",
    "    neighs = NearestNeighbors(n_neighbors=num_neighs+1) #add plus one in case image exists in database\n",
    "    neighs.fit(database_features)\n",
    "    distance, nn_index = neighs.kneighbors(query_features, return_distance=True)\n",
    "    \n",
    "    #Check to see if image is already in dabase and remove (see if distance == 0)\n",
    "    #If True, remove n = 0, and take n+1 neighbor\n",
    "    if remove_dup: \n",
    "        updated_nn_index = []\n",
    "        for i,row in enumerate(distance):\n",
    "            image_exists = len(nn_index[i, row!=0]) == num_neighs\n",
    "            if image_exists: \n",
    "                new_in= nn_index[i,1:num_neighs+1]\n",
    "            else: \n",
    "                new_in = nn_index[i,0:num_neighs]\n",
    "        \n",
    "            updated_nn_index.append(new_in)\n",
    "    \n",
    "        nn_index = np.array(updated_nn_index)\n",
    "    \n",
    "    #Get pandas dataframes\n",
    "    panda_list = []\n",
    "    for row in nn_index: \n",
    "        panda_list.append(price_filter_df.iloc[row])\n",
    "    \n",
    "    #Get nearest neighbor result urls \n",
    "    url_matrix = []\n",
    "    for row in nn_index: \n",
    "        url_row = price_filter_df['image_url'].values[row]\n",
    "        url_matrix.append(url_row)\n",
    "    \n",
    "    url_matrix = np.array(url_matrix)\n",
    "\n",
    "    #concat query image array to result arrays \n",
    "    images_urls = np.concatenate([query_image, url_matrix], axis = 1)\n",
    "\n",
    "    if fig_plot: \n",
    "        get_fig_plots(images_urls)\n",
    "\n",
    "    return(nn_index, images_urls, panda_list)  \n",
    "            \n",
    "def get_fig_plots(image_urls):\n",
    "    ''' function to plot matrix of image urls. \n",
    "        image_urls[:,0] should be the query image\n",
    "        \n",
    "    Args: \n",
    "        image_urls: matrix of image urls\n",
    "    \n",
    "    return: \n",
    "        null\n",
    "        saves image file to directory\n",
    "    '''\n",
    "    nrow = image_urls.shape[0]\n",
    "    ncol = image_urls.shape[1]\n",
    "    flat_urls = image_urls.flatten()\n",
    "\n",
    "    fig = plt.figure(figsize = (20, 20))\n",
    "\n",
    "    for num,url in enumerate(flat_urls):\n",
    "    \n",
    "        response = requests.get(url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        img = img.resize((224,224), Image.ANTIALIAS)\n",
    "        plt.subplot(nrow, ncol, num+1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(img);\n",
    "\n",
    "        if num == 0: \n",
    "            plt.title('Query')\n",
    "    \n",
    "        if 0<num <ncol: \n",
    "            plt.title('Neighbor ' + str(num))\n",
    "        \n",
    "    plt.savefig('image_search.png')\n",
    "        \n",
    "    \n",
    "            \n",
    "#Test Nearest Neighbor lookup with random selection from database, plot results \n",
    "n_queries = 1\n",
    "query_inds = []\n",
    "random.seed(150)\n",
    "[query_inds.append(random.randint(i,12000)) for i in range(n_queries)]\n",
    "\n",
    "query_features = np.vstack(image_df['image_features'][query_inds])\n",
    "query_url = np.array(image_df['image_url'][query_inds]).reshape(n_queries,1)\n",
    "num_neigs = 5\n",
    "fig_plot = 1\n",
    "indices, urls, subset_pd = nearest_neighbor_image_finder(query_url, query_features, num_neighs, image_df,fig_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOW A FEW THINGS\n",
    "# train the model to \"classify\" (for validation)\n",
    "# use the pre-trained model to look at how the features are distributed in space from MobileNetV2\n",
    "\n",
    "print(tr_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model saving\n",
    "checkpoint = ModelCheckpoint(model_name+'.h5',monitor='val_acc',verbose=1,save_best_only=True)\n",
    "early_stop = EarlyStopping(monitor='val_acc',min_delta=0,patience=10,verbose=1,mode='auto')\n",
    "\n",
    "# Compile the model\n",
    "#adam = Adam()\n",
    "tr_model.compile(loss='categorical_crossentropy', optimizer = \"nadam\" ,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "history = tr_model.fit_generator(\n",
    "                train_gen,\n",
    "                steps_per_epoch=1000,\n",
    "                epochs=30,\n",
    "                validation_data = val_gen,\n",
    "                validation_steps = 250,\n",
    "                callbacks = [checkpoint, early_stop] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "plt.figure()\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model_accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'])\n",
    "plt.savefig(args.model_name+'.jpg')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def central_crop(image):\n",
    "    shape = tf.shape(image)\n",
    "    min_dim = tf.reduce_min([shape[0], shape[1]])\n",
    "    top_crop = (shape[0] - min_dim) // 4\n",
    "    bottom_crop = shape[0] - top_crop\n",
    "    left_crop = (shape[1] - min_dim) // 4\n",
    "    right_crop = shape[1] - left_crop\n",
    "    return image[top_crop:bottom_crop, left_crop:right_crop]\n",
    "\n",
    "\n",
    "def preprocess(image, label, randomize=False):\n",
    "    if randomize:\n",
    "        cropped_image = random_crop(image)\n",
    "        cropped_image = tf.image.random_flip_left_right(cropped_image)\n",
    "    else:\n",
    "        cropped_image = central_crop(image)\n",
    "    resized_image = tf.image.resize(cropped_image, [224, 224])\n",
    "    final_image = keras.applications.xception.preprocess_input(resized_image)\n",
    "    return final_image, label\n",
    "\n",
    "batch_size = 32\n",
    "train_set = train_set_raw.shuffle(1000).repeat()\n",
    "train_set = train_set.map(partial(preprocess, randomize=True)).batch(batch_size).prefetch(1)\n",
    "valid_set = valid_set_raw.map(preprocess).batch(batch_size).prefetch(1)\n",
    "test_set = test_set_raw.map(preprocess).batch(batch_size).prefetch(1)\n",
    "\n",
    "images_resized = tf.image.resize(images, [224, 224])\n",
    "plot_color_image(images_resized[0])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "def plot_image(image):\n",
    "    plt.imshow(image, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    \n",
    "def preprocess(image, label):\n",
    "    resized_image = tf.image.resize(image, [224, 224])\n",
    "    final_image = keras.applications.xception.preprocess_input(resized_image)\n",
    "    return final_image, label\n",
    "\n",
    "\n",
    "\n",
    "test_split, valid_split, train_split = tfds.Split.TRAIN.subsplit([10, 15, 75])\n",
    "\n",
    "test_set_raw = tfds.load(\"tf_flowers\", split=test_split, as_supervised=True)\n",
    "valid_set_raw = tfds.load(\"tf_flowers\", split=valid_split, as_supervised=True)\n",
    "train_set_raw = tfds.load(\"tf_flowers\", split=train_split, as_supervised=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_df = pandas.read_csv(\"./train.csv\")\n",
    "valid_df = pandas.read_csv(\"./valid.csv\")\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "        dataframe=train_df,\n",
    "        directory='data/train',\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"class\",\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_dataframe(\n",
    "        dataframe=valid_df,\n",
    "        directory='data/validation',\n",
    "        x_col=\"filename\",\n",
    "        y_col=\"class\",\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folderpath = df_clean.path\n",
    "#files = data_folderpath.to_list()\n",
    "filepaths = data_folderpath.to_list()\n",
    "len(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepaths = glob(glob_str)\n",
    "batch_size = 1024\n",
    "img_size = 224\n",
    "n_files = len(filepaths)\n",
    "cur_batch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    # drop last if it does not fit\n",
    "    if (n_files - cur_batch*batch_size) < batch_size or cur_batch == 0:\n",
    "        ids = np.random.randint(0, n_files, n_files)\n",
    "        np.random.shuffle(ids)\n",
    "        cur_batch = 0\n",
    "    train_data = []\n",
    "    for i in range(batch_size):\n",
    "        image_ab = load_image(filepaths[ids[cur_batch*batch_size+i]])\n",
    "        train_data.append([image_ab[:, :img_size], image_ab[:, img_size:]])\n",
    "\n",
    "    cur_batch = (cur_batch + 1) % int(len(filepaths)/batch_size)\n",
    "\n",
    "    train_data = np.array(train_data)\n",
    "#    yield train_data, cur_batch\n",
    "\n",
    "\n",
    "\n",
    "#data=ImageDataBunch.from_df(path=\"ut-zap50k-images-square/\",df=df_clean, size=224,bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folderpath = df_clean.path\n",
    "\n",
    "files = data_folderpath.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(files[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = create_minibatches(data_folderpath.to_list, 128, 224)\n",
    "#        data_folderpath + \"/train/*.jpg\", batch_size, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_data_iterator = iterate_minibatches(\n",
    "#         data_folderpath + \"/val/*.jpg\", n_checkpoint_samples, image_size)\n",
    "\n",
    "\n",
    "img_ab_fixed, _ = next(data_iterator)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator\n",
    "\n",
    "\n",
    "#al_data_iterator = iterate_minibatches(data_folderpath + \"/val/*.jpg\", n_checkpoint_samples, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from keras.applications.mobilenet_v2 import preprocess_input\n",
    "from keras.applications import imagenet_utils\n",
    "\n",
    "global pwidth\n",
    "global pheight\n",
    "global network_model\n",
    "\n",
    "pwidth = 224\n",
    "pheight = 224\n",
    "    \n",
    "global graph \n",
    "graph = tf.get_default_graph()\n",
    "network_model = MobileNetV2(weights = 'imagenet', include_top = False, input_shape = (pwidth,pheight,3),pooling = 'avg')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img_data = image.load_img(img_path, target_size=(pwidth, pheight))\n",
    "img_vector = image.img_to_array(img_data)\n",
    "img_vector = np.expand_dims(img_vector, axis=0)\n",
    "img_vector = preprocess_input(img_vector) #Problem here, must be convention of keras to pass by reference?\n",
    "img_vector = imagenet_utils.preprocess_input(img_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_features = network_model.predict(img_vector)\n",
    "\n",
    "#Get pandas df of n clo\n",
    "nn_index, neighbors_df = nearest_neighbor_image_finder(img_features, 100, database_df,0,100,100)\n",
    "neighbors = neighbors_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbor_image_finder(query_features, num_neighs, database, price_filt, min_price, max_price,): \n",
    "    ''' function to return nearest neighbors for a query\n",
    "    \n",
    "    Args: \n",
    "        query_features (array): numpy array of extracted image features\n",
    "        num_neighs (int): number of neighbors to return \n",
    "        datbase(df): pandas dataframe containing image database\n",
    "        fig_plot (bool): boolean to indicate of plotting is desired (1 for yes)\n",
    "        min_price (float): minimum budget\n",
    "        max_price (float): max budget\n",
    "        remove_dup (bool): remove image from database if it exists\n",
    "    \n",
    "    return: \n",
    "        nn_results: indices of nearest_neighbor lookup\n",
    "        neighbor_pd: pandas dataframe subsetted on returned values from knn search\n",
    "    '''\n",
    "    #########################################\n",
    "    ''' i don't actually want nearest neighbors.... maybe an average or latent images and the text.\n",
    "        should return text.\n",
    "    '''\n",
    "    # #############################################\n",
    "    #Filter Database based on given price range\n",
    "    if price_filt:\n",
    "        database  = database[(database['price']< max_price) & (database['price']> min_price)]\n",
    "    \n",
    "    #logic here in case the n exceeds number of items in database\n",
    "    size_filter_frame = database.shape[0]\n",
    "    num_neighs = min(num_neighs, size_filter_frame)\n",
    "    \n",
    "    #Fit Nearest Neighbor Model\n",
    "    database_features = np.vstack(database['image_features'])\n",
    "    neighs = NearestNeighbors(n_neighbors=num_neighs) \n",
    "    neighs.fit(database_features)\n",
    "    distance, nn_index = neighs.kneighbors(query_features, return_distance=True)\n",
    "\n",
    "    #Get nearest neighbor subset\n",
    "    neighbor_pd = []\n",
    "    for row in nn_index: \n",
    "        neighbor_pd.append(database.iloc[row])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_iterator = iterate_minibatches(data\n",
    "#         data_folderpath + \"/train/*.jpg\", batch_size, image_size)\n",
    "# val_data_iterator = iterate_minibatches(\n",
    "#         data_folderpath + \"/val/*.jpg\", n_checkpoint_samples, image_size)\n",
    "\n",
    "img_ab_fixed, _ = next(val_data_iterator)\n",
    "# img_a_fixed, img_b_fixed = img_ab_fixed[:, 0], img_ab_fixed[:, 1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ones = np.ones((batch_size, ) + disc_patch, dtype=np.float32)\n",
    "    zeros = np.zeros((batch_size, ) + disc_patch, dtype=np.float32)\n",
    "    dummy = zeros\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        D.trainable = True\n",
    "        G.trainable = False\n",
    "\n",
    "        image_ab_batch, _ = next(data_iterator)\n",
    "        loss_d = D_model.train_on_batch(\n",
    "            [image_ab_batch[:, 0], image_ab_batch[:, 1]],\n",
    "            [ones, zeros])\n",
    "\n",
    "        D.trainable = False\n",
    "        G.trainable = True\n",
    "        image_ab_batch, _ = next(data_iterator)\n",
    "        loss_g = G_model.train_on_batch(\n",
    "            [image_ab_batch[:, 0], image_ab_batch[:, 1]],\n",
    "            [ones, dummy])\n",
    "\n",
    "        print(\"iter\", i)\n",
    "        if (i % iters_per_checkpoint) == 0:\n",
    "            G.trainable = False\n",
    "            fake_image = G.predict(img_a_fixed)\n",
    "            log_images(fake_image, 'val_fake', i, logger)\n",
    "            save_model(G, out_dir)\n",
    "\n",
    "        log_losses(loss_d, loss_g, i, logger)\n",
    "\n",
    "        \n",
    "\n",
    "# #n = 12856 images\n",
    "# # images are \"path\"\n",
    "\n",
    "# # now need to split into test train for sci-kit learn\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "# ...     X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "dataframe = df_clean #pandas.read_csv(\"INPUTFILE.csv\", skiprows=range(0, 0))\n",
    "\n",
    "dataset = dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,0:50].astype(float) # number of cols-1\n",
    "Y = dataset[:,50]\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "encoded_Y = np_utils.to_categorical(encoded_Y)\n",
    "print(\"encoded_Y=\", encoded_Y) \n",
    "# baseline model\n",
    "def create_baseline():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(5, input_dim=5, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(5, kernel_initializer='normal', activation='relu'))\n",
    "    #model.add(Dense(2, kernel_initializer='normal', activation='sigmoid'))\n",
    "\n",
    "    model.add(Dense(2, kernel_initializer='normal', activation='softmax'))\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  # for binayr classification\n",
    "        #model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  # for multi class\n",
    "    return model\n",
    "\n",
    "\n",
    "model=create_baseline();\n",
    "history=model.fit(X, encoded_Y, batch_size=50, nb_epoch=500, validation_split = 0.2, verbose=1)\n",
    "\n",
    "print(history.history.keys())\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "pre_cls=model.predict_classes(X)    \n",
    "cm1 = confusion_matrix(encoder.transform(Y),pre_cls)\n",
    "print('Confusion Matrix : \\n')\n",
    "print(cm1)\n",
    "\n",
    "\n",
    "score, acc = model.evaluate(X,encoded_Y)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:zapposGPU]",
   "language": "python",
   "name": "conda-env-zapposGPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "523.975px",
    "left": "1161.26px",
    "right": "20px",
    "top": "120px",
    "width": "688.223px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
